{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem statement:\n",
    "https://gym.openai.com/envs/MsPacman-v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyvirtualdisplay in /usr/local/lib/python2.7/dist-packages\n",
      "Requirement already satisfied: EasyProcess in /usr/local/lib/python2.7/dist-packages (from pyvirtualdisplay)\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import gym\n",
    "import random\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from DDQN_agent_Atari_3D_PReplay_Tree import Agent\n",
    "from myWrappers import StackEnv\n",
    "\n",
    "!python -m pip install pyvirtualdisplay\n",
    "from pyvirtualdisplay import Display\n",
    "display = Display(visible=0, size=(1400, 900))\n",
    "display.start()\n",
    "\n",
    "is_ipython = 'inline' in plt.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State shape:  (210, 160, 3)\n",
      "Number of actions:  9\n"
     ]
    }
   ],
   "source": [
    "# Original Gym Env basic info\n",
    "env = gym.make('MsPacman-v0')\n",
    "env.seed(0)\n",
    "state_space = env.observation_space.shape\n",
    "action_space = env.action_space.n\n",
    "input_shape = (84,84)\n",
    "states_stack_depth = 4\n",
    "print('State shape: ', state_space)\n",
    "print('Number of actions: ', action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f60ba80d780>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAloAAAD6CAYAAAB52OktAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6049dd8710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#import images\n",
    "s = env.reset()\n",
    "s0, s1, s2 = None, None, None\n",
    "\n",
    "sampleframe = 240\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize=(10,6)) \n",
    "for i in range(1000):\n",
    "    s, r, d, _ = env.step(1)\n",
    "    if i == sampleframe:\n",
    "        s0 = s\n",
    "    if i == (sampleframe+1):\n",
    "        s1= s\n",
    "    if i == (sampleframe+2):\n",
    "        s2= s\n",
    "ax1.imshow(s0)\n",
    "ax2.imshow(s1)\n",
    "ax3.imshow(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to get all the preprosing logic done in this class\n",
    "from myWrappers import StackEnv\n",
    "stackenv = StackEnv(gym.make('MsPacman-v0'))\n",
    "\n",
    "model_dir = 'saved_models/'\n",
    "model_name = 'MsPacman-v1-3D-all-dicts-AWS-tree.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 84, 84)\n"
     ]
    }
   ],
   "source": [
    "s = stackenv.reset()\n",
    "ns, r, d = stackenv.step(0)\n",
    "print(ns.shape)\n",
    "\n",
    "stackenv.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASQAAAFpCAYAAAA1P1VeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f60ad47c208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "untrained_agent = Agent(state_size=states_stack_depth, action_size=action_space, seed=10)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# watch an untrained agent\n",
    "stackenv = StackEnv(gym.make('MsPacman-v0'), skipframe=2)\n",
    "state_inputs = stackenv.reset()\n",
    "\n",
    "img = ax.imshow(stackenv.env.render(mode='rgb_array'))\n",
    "for j in range(1000):\n",
    "    #action = untrained_agent.act(state_inputs)\n",
    "    action = np.random.choice(action_space)\n",
    "    img.set_data(stackenv.env.render(mode='rgb_array')) \n",
    "    plt.axis('off')\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)\n",
    "\n",
    "    next_state_inputs, reward, done = stackenv.step(action)\n",
    "    state_inputs = next_state_inputs\n",
    "    \n",
    "    if done:\n",
    "        break \n",
    "        \n",
    "stackenv.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadTrainedModel(agent, path):\n",
    "    state_dicts = torch.load(path)\n",
    "    print(state_dicts['model'].keys())\n",
    "\n",
    "    agent.qnetwork_local.load_state_dict(state_dicts['model'])\n",
    "    agent.optimizer.load_state_dict(state_dicts['optimizer'])\n",
    "    \n",
    "    return agent, state_dicts['eps'], state_dicts['n_episodes'], state_dicts['i_episode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveTrainedModel(agent, path, eps, n_episodes, i_episode):\n",
    "    state_dicts = {'model': agent.qnetwork_local.state_dict(), \n",
    "                   'optimizer': agent.optimizer.state_dict(),\n",
    "                   'eps': eps, \n",
    "                   'n_episodes': n_episodes,\n",
    "                   'i_episode': i_episode\n",
    "                  }\n",
    "    torch.save(state_dicts, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current device: cuda:0\n",
      "use duel network (a and v): True\n",
      "use double network: True\n",
      "use reward scaling: False\n",
      "use error clipping: True\n",
      "buffer size: 100000\n",
      "batch size: 64\n",
      "learning rate: 0.0002\n",
      "min replay size: 100000\n",
      "target network update: 1000\n",
      "optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0002\n",
      "    weight_decay: 0\n",
      ")\n",
      "QNetwork(\n",
      "  (conv1): Conv2d(4, 32, kernel_size=(8, 8), stride=(4, 4))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
      "  (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1a): Linear(in_features=3136, out_features=512, bias=True)\n",
      "  (fc3a): Linear(in_features=512, out_features=9, bias=True)\n",
      "  (fc1v): Linear(in_features=3136, out_features=512, bias=True)\n",
      "  (fc3v): Linear(in_features=512, out_features=1, bias=True)\n",
      ")\n",
      "odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'conv3.weight', 'conv3.bias', 'fc1a.weight', 'fc1a.bias', 'fc3a.weight', 'fc3a.bias', 'fc1v.weight', 'fc1v.bias', 'fc3v.weight', 'fc3v.bias'])\n"
     ]
    }
   ],
   "source": [
    "model_dir = 'saved_models/'\n",
    "model_name = 'MsPacman-v1-3D-all-dicts-local.pt'\n",
    "\n",
    "agent = Agent(state_size=states_stack_depth, action_size=action_space, seed=0)\n",
    "print(agent.qnetwork_local)\n",
    "\n",
    "loadSavedModel = True\n",
    "\n",
    "if loadSavedModel == True:\n",
    "    agent, eps, n_episodes, i_episode = loadTrainedModel(agent, model_dir+model_name)\n",
    "    eps = 1.0\n",
    "    n_episodes = 5000\n",
    "    i_episode = 1\n",
    "else:\n",
    "    eps = 1.0\n",
    "    n_episodes = 10000\n",
    "    i_episode = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training to be started... Steps: 99896 training starts!                            \n",
      "Episode: 100\tAvg Score: 373.10\tsteps: 116225\teps: 0.98\tlr: 2.00e-04\tp: 0.700  b: 0.510\n",
      "Episode: 200\tAvg Score: 422.40\tsteps: 133481\teps: 0.97\tlr: 2.00e-04\tp: 0.700  b: 0.520\n",
      "Episode: 300\tAvg Score: 418.30\tsteps: 150908\teps: 0.95\tlr: 2.00e-04\tp: 0.700  b: 0.530\n",
      "Episode: 400\tAvg Score: 430.60\tsteps: 168125\teps: 0.94\tlr: 2.00e-04\tp: 0.700  b: 0.540\n",
      "Episode: 500\tAvg Score: 420.80\tsteps: 184976\teps: 0.92\tlr: 2.00e-04\tp: 0.700  b: 0.550\n",
      "Episode: 600\tAvg Score: 449.40\tsteps: 202450\teps: 0.90\tlr: 2.00e-04\tp: 0.700  b: 0.560\n",
      "Episode: 700\tAvg Score: 436.20\tsteps: 219404\teps: 0.89\tlr: 2.00e-04\tp: 0.700  b: 0.570\n",
      "Episode: 800\tAvg Score: 415.30\tsteps: 236156\teps: 0.88\tlr: 2.00e-04\tp: 0.700  b: 0.580\n",
      "Episode: 900\tAvg Score: 499.50\tsteps: 254737\teps: 0.86\tlr: 2.00e-04\tp: 0.700  b: 0.590\n",
      "Episode: 1000\tAvg Score: 487.00\tsteps: 272445\teps: 0.85\tlr: 2.00e-04\tp: 0.700  b: 0.600\n",
      "Episode: 1100\tAvg Score: 484.10\tsteps: 290089\teps: 0.83\tlr: 2.00e-04\tp: 0.700  b: 0.610\n",
      "Episode: 1200\tAvg Score: 479.90\tsteps: 307483\teps: 0.82\tlr: 2.00e-04\tp: 0.700  b: 0.620\n",
      "Episode: 1300\tAvg Score: 462.50\tsteps: 324379\teps: 0.81\tlr: 2.00e-04\tp: 0.700  b: 0.630\n",
      "Episode: 1400\tAvg Score: 458.60\tsteps: 341883\teps: 0.79\tlr: 2.00e-04\tp: 0.700  b: 0.640\n",
      "Episode: 1500\tAvg Score: 485.60\tsteps: 359459\teps: 0.78\tlr: 2.00e-04\tp: 0.700  b: 0.650\n",
      "Episode: 1600\tAvg Score: 542.90\tsteps: 378091\teps: 0.77\tlr: 2.00e-04\tp: 0.700  b: 0.660\n",
      "Episode: 1700\tAvg Score: 501.20\tsteps: 396763\teps: 0.75\tlr: 2.00e-04\tp: 0.700  b: 0.670\n",
      "Episode: 1800\tAvg Score: 511.10\tsteps: 414277\teps: 0.74\tlr: 2.00e-04\tp: 0.700  b: 0.680\n",
      "Episode: 1900\tAvg Score: 526.80\tsteps: 431856\teps: 0.73\tlr: 2.00e-04\tp: 0.700  b: 0.690\n",
      "Episode: 2000\tAvg Score: 493.20\tsteps: 449243\teps: 0.72\tlr: 2.00e-04\tp: 0.700  b: 0.700\n",
      "Episode: 2100\tAvg Score: 538.40\tsteps: 467436\teps: 0.70\tlr: 2.00e-04\tp: 0.700  b: 0.710\n",
      "Episode: 2200\tAvg Score: 501.20\tsteps: 485291\teps: 0.69\tlr: 2.00e-04\tp: 0.700  b: 0.720\n",
      "Episode: 2300\tAvg Score: 521.20\tsteps: 503022\teps: 0.68\tlr: 2.00e-04\tp: 0.700  b: 0.730\n",
      "Episode: 2400\tAvg Score: 541.90\tsteps: 521184\teps: 0.67\tlr: 2.00e-04\tp: 0.700  b: 0.740\n",
      "Episode: 2500\tAvg Score: 548.20\tsteps: 539235\teps: 0.66\tlr: 2.00e-04\tp: 0.700  b: 0.750\n",
      "Episode: 2600\tAvg Score: 545.90\tsteps: 557270\teps: 0.65\tlr: 2.00e-04\tp: 0.700  b: 0.760\n",
      "Episode: 2700\tAvg Score: 585.10\tsteps: 576524\teps: 0.64\tlr: 2.00e-04\tp: 0.700  b: 0.770\n",
      "Episode: 2800\tAvg Score: 539.10\tsteps: 595049\teps: 0.63\tlr: 2.00e-04\tp: 0.700  b: 0.780\n",
      "Episode: 2900\tAvg Score: 636.80\tsteps: 614875\teps: 0.62\tlr: 2.00e-04\tp: 0.700  b: 0.790\n",
      "Episode: 3000\tAvg Score: 519.60\tsteps: 632670\teps: 0.61\tlr: 2.00e-04\tp: 0.700  b: 0.800\n",
      "Episode: 3100\tAvg Score: 578.80\tsteps: 650755\teps: 0.60\tlr: 2.00e-04\tp: 0.700  b: 0.810\n",
      "Episode: 3200\tAvg Score: 622.70\tsteps: 669568\teps: 0.59\tlr: 2.00e-04\tp: 0.700  b: 0.820\n",
      "Episode: 3300\tAvg Score: 657.90\tsteps: 688894\teps: 0.58\tlr: 2.00e-04\tp: 0.700  b: 0.830\n",
      "Episode: 3400\tAvg Score: 658.20\tsteps: 708290\teps: 0.57\tlr: 2.00e-04\tp: 0.700  b: 0.840\n",
      "Episode: 3500\tAvg Score: 819.60\tsteps: 730789\teps: 0.56\tlr: 2.00e-04\tp: 0.700  b: 0.850\n",
      "Episode: 3600\tAvg Score: 608.30\tsteps: 751359\teps: 0.55\tlr: 2.00e-04\tp: 0.700  b: 0.860\n",
      "Episode: 3700\tAvg Score: 661.90\tsteps: 773174\teps: 0.54\tlr: 2.00e-04\tp: 0.700  b: 0.870\n",
      "Episode: 3800\tAvg Score: 563.00\tsteps: 792355\teps: 0.53\tlr: 2.00e-04\tp: 0.700  b: 0.880\n",
      "Episode: 3900\tAvg Score: 565.30\tsteps: 811869\teps: 0.52\tlr: 2.00e-04\tp: 0.700  b: 0.890\n",
      "Episode: 4000\tAvg Score: 565.90\tsteps: 831353\teps: 0.51\tlr: 2.00e-04\tp: 0.700  b: 0.900\n",
      "Episode: 4100\tAvg Score: 569.40\tsteps: 850859\teps: 0.50\tlr: 2.00e-04\tp: 0.700  b: 0.910\n",
      "Episode: 4200\tAvg Score: 659.00\tsteps: 871058\teps: 0.50\tlr: 2.00e-04\tp: 0.700  b: 0.920\n",
      "Episode: 4300\tAvg Score: 543.60\tsteps: 889146\teps: 0.49\tlr: 2.00e-04\tp: 0.700  b: 0.930\n",
      "Episode: 4400\tAvg Score: 608.30\tsteps: 909411\teps: 0.48\tlr: 2.00e-04\tp: 0.700  b: 0.940\n",
      "Episode: 4500\tAvg Score: 675.40\tsteps: 928759\teps: 0.47\tlr: 2.00e-04\tp: 0.700  b: 0.950\n",
      "Episode: 4600\tAvg Score: 655.90\tsteps: 947571\teps: 0.46\tlr: 2.00e-04\tp: 0.700  b: 0.960\n",
      "Episode: 4700\tAvg Score: 739.20\tsteps: 966954\teps: 0.46\tlr: 2.00e-04\tp: 0.700  b: 0.970\n",
      "Episode: 4800\tAvg Score: 669.80\tsteps: 986494\teps: 0.45\tlr: 2.00e-04\tp: 0.700  b: 0.980\n",
      "Episode: 4900\tAvg Score: 717.10\tsteps: 1006337\teps: 0.44\tlr: 2.00e-04\tp: 0.700  b: 0.990\n",
      "Episode: 4999\tAvg Score: 638.30\tb: 1.000"
     ]
    }
   ],
   "source": [
    "def dqn_3D(n_episodes=1000, i_episode=1, max_t=1000, eps_start=1.0, eps_end=0.05, eps_decay=0.9995):\n",
    "    \"\"\"Deep Q-Learning.\n",
    "    \n",
    "    Params\n",
    "    ======\n",
    "        n_episodes (int): maximum number of training episodes\n",
    "        max_t (int): maximum number of timesteps per episode\n",
    "        eps_start (float): starting value of epsilon, for epsilon-greedy action selection\n",
    "        eps_end (float): minimum value of epsilon\n",
    "        eps_decay (float): multiplicative factor (per episode) for decreasing epsilon\n",
    "    \"\"\"\n",
    "    stackenv = StackEnv(gym.make('MsPacman-v0'))\n",
    "    \n",
    "    scores = []                        # list containing scores from each episode\n",
    "    scores_window = deque(maxlen=100)  # last 100 scores\n",
    "    frame_counter = 0                  # keep track of number of frames seen\n",
    "    \n",
    "    eps = eps_start                    # initialize epsilon \n",
    "    eps_decay=1-1/(n_episodes+1000)    # make sure decay come to min \n",
    "    \n",
    "    while i_episode < n_episodes + 1:\n",
    "        \n",
    "        state_inputs = stackenv.reset()    \n",
    "        score = 0\n",
    "\n",
    "        for t in range(max_t):\n",
    "\n",
    "            action = agent.act(state_inputs, eps) #for action recommendation\n",
    "            \n",
    "            next_state_inputs, reward, done = stackenv.step(action)\n",
    "            \n",
    "            frame_counter += 1\n",
    "            \n",
    "            agent.step(state_inputs , action, reward, next_state_inputs, done, (i_episode,n_episodes))\n",
    "            \n",
    "            state_inputs = next_state_inputs\n",
    "            \n",
    "            score += reward\n",
    "            \n",
    "            if done:\n",
    "                break \n",
    "                \n",
    "        if agent.isTraining == True:     #learning starts   \n",
    "            scores_window.append(score)       # save most recent score\n",
    "            scores.append(score)              # save most recent score\n",
    "\n",
    "            eps = max(eps_end, eps_decay*eps) # decay epsilon\n",
    "\n",
    "            print('\\rEpisode: {}\\tAvg Score: {:.2f}\\tb: {:.3f}'.format(i_episode, \n",
    "                                                                       np.mean(scores_window),\n",
    "                                                                       agent.p_replay_beta\n",
    "                                                                      ), end=\"\")\n",
    "\n",
    "            if i_episode % 100 == 0:\n",
    "                latest_lr = agent.optimizer.state_dict()['param_groups'][0]['lr']\n",
    "\n",
    "                print(('\\rEpisode: {}\\tAvg Score: {:.2f}\\tsteps: {}\\teps: {:.2f}'\n",
    "                       '\\tlr: {:1.2e}\\tp: {:.3f}  b: {:.3f}').format(i_episode, np.mean(scores_window),\n",
    "                                                                     agent.t_step, eps, latest_lr, \n",
    "                                                                     agent.p_replay_alpha, \n",
    "                                                                     agent.p_replay_beta, end=\"\")) \n",
    "\n",
    "                saveTrainedModel(agent, model_dir+model_name, eps, n_episodes, i_episode)\n",
    "\n",
    "            if np.mean(scores_window)>=2500.0:\n",
    "                print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode-100,\n",
    "                                                                                             np.mean(scores_window)))\n",
    "\n",
    "                saveTrainedModel(agent, model_dir+model_name, eps, n_episodes, i_episode)\n",
    "                break\n",
    "            \n",
    "            i_episode += 1\n",
    "        else:\n",
    "            print('\\rTraining to be started... Steps: {} '.format(agent.t_step), end=\"\")\n",
    "\n",
    "    stackenv.close()\n",
    "        \n",
    "    return scores\n",
    "\n",
    "scores = dqn_3D(n_episodes, i_episode=i_episode, eps_start=eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASQAAAFpCAYAAAA1P1VeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyBAkIEOQgAxBAjIECcgQJCDj/8/25tcuV5ZNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4a02979be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the weights from file\n",
    "#torch.load(agent.qnetwork_local.state_dict(), model_dir+model_name)\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "stackenv = StackEnv(gym.make('MsPacman-v0'), skipframe=4)\n",
    "\n",
    "agent.qnetwork_local.eval()\n",
    "agent.qnetwork_target.eval()\n",
    "\n",
    "for i in range(3):\n",
    "    # watch an untrained agent\n",
    "    state_inputs = stackenv.reset()  \n",
    "    \n",
    "    img = ax.imshow(stackenv.env.render(mode='rgb_array'))\n",
    "    for j in range(1000):\n",
    "        action = agent.act(state_inputs)\n",
    "        img.set_data(stackenv.env.render(mode='rgb_array')) \n",
    "        plt.axis('off')\n",
    "        display.display(plt.gcf())\n",
    "        display.clear_output(wait=True)\n",
    "        next_state_inputs, reward, done = stackenv.step(action)\n",
    "        \n",
    "        state_inputs = next_state_inputs\n",
    "        \n",
    "        if done:\n",
    "            break \n",
    "\n",
    "agent.qnetwork_local.train()\n",
    "#agent.qnetwork_target.train()\n",
    "            \n",
    "stackenv.env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
